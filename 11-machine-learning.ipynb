{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import math\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import library_data_science as lds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Multi-Dimentional Data\n",
    "\n",
    "\n",
    "Multi-dimensional data can be represented as an array of tuples, where each tuple consists one, two or more elements. In this structure, the first element in each tuple is treated as independent, while the another elements typically depends on the first, reflecting the relationship between the variables. \\\n",
    "Remember that `D.size = n` and $\\forall{m < n}($ `D[m].size = k`$)$.\n",
    "\n",
    "$$D =  \\bigg< (d_{00}, d_{01}, ..., d_{0(k-1)}), (d_{10}, d_{11}, ..., d_{1(k-1)}), (d_{20}, d_{21}, ..., d_{2(k-1)}), ... , (d_{(n-1)0}, d_{(n-1)1}, ..., d_{(n-1)(k-1)}) \\bigg>,$$\n",
    "$$D = \\bigg< (D[0][0], D[0][1], ..., D[0][k-1]), (D[1][0], D[1][1], ..., D[1][k-1]), ..., (D[n-1][0], D[n-1][1], ..., D[n-1][k-1]) \\bigg>$$\n",
    "\n",
    "Multi-dimentional dataset can be unzipped to the $k$ separated sets.\n",
    "\n",
    "$$D_0 = \\big< d_{00}, d_{10}, ... , d_{(n-1)0} \\big> = \\big< D[0][0], D[1][0], ... , D[n-1][0] \\big> $$\n",
    "$$D_1 = \\big< d_{01}, d_{11}, ... , d_{(n-1)1} \\big> = \\big< D[0][1], D[1][1], ... , D[n-1][1] \\big>$$\n",
    "$$...$$\n",
    "$$D_{k-1} = \\big< d_{0(k-1)}, d_{1(k-1)}, ... , d_{(n-1)(k-1)} \\big> = \\big< D[0][k-1], D[1][k-1], ... , D[n-1][k-1] \\big>$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate the difference, I will use the example I used in the presentation to explain what multidimensional data are.\n",
    "\n",
    "#### Example 1: Runners' Performance\n",
    "\n",
    "When examining the distances covered by runners during a 5-minute run, along with their heart rates and oxygen consumption, our data will no longer be one-dimensional. Instead, it will consist of multiple attributes for each runner.\n",
    "\n",
    "$$\n",
    "Distance\\_Heart\\_Oxygen = \\big< (1078, 145, 3.2), (896, 152, 2.9), (1196, 138, 3.5), (1009, 149, 3.1), (1078, 143, 3.3), (1096, 141, 3.4), (923, 155, 3.0) \\big>\n",
    "$$\n",
    "\n",
    "Here, each tuple represents **(distance in meters, heart rate in bpm, oxygen consumption in L/min)**, making it a **three-dimensional dataset**.\n",
    "\n",
    "$$\n",
    "Distance = \\big<1078, 896, 1196, 1009, 1078, 1096, 923> \\\\\n",
    "Heart = \\big<145, 152, 138, 149, 143, 141, 155> \\\\\n",
    "Oxygen = \\big<3.2, 2.9, 3.5, 3.1, 3.3, 3.4, 3.0>\n",
    "$$\n",
    "\n",
    "#### Example 2: Physiological and Lifestyle Factors\n",
    "\n",
    "When studying multiple physiological and lifestyle factors influencing body weight, a more complex dataset may include height, body weight, age, and daily caloric intake.\n",
    "\n",
    "$$\n",
    "Weights\\_Heights\\_Ages\\_Calories = \\big< (60, 177, 25, 2200), (76, 189, 30, 2500), (99, 197, 28, 2700), (48, 165, 22, 1800) \\big>\n",
    "$$\n",
    "\n",
    "Each entry now contains four attributes, making it a **four-dimensional dataset**.\n",
    "\n",
    "$$\n",
    "Weights = \\big< 60, 76, 99, 48 \\big> \\\\\n",
    "Heights = \\big< 177, 189, 197, 165 \\big> \\\\\n",
    "Ages = \\big< 25, 30, 28, 22 \\big> \\\\\n",
    "Calories = \\big< 2200, 2500, 2700, 1800 \\big>\n",
    "$$\n",
    "\n",
    "#### Key Takeaways\n",
    "\n",
    "The more attributes we include in our dataset, the higher its dimensionality. Multidimensional data allow for deeper analysis, such as finding correlations between different factors, but they also introduce challenges like increased complexity in visualization and computational processing. \n",
    "\n",
    "**Machine learning techniques, such as Principal Component Analysis (PCA), can help reduce dimensionality while preserving essential information.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "**Machine Learning (ML)** is a branch of artificial intelligence (AI) that enables computers to recognize patterns and make decisions based on dataâ€”without the need for explicitly programmed rules.\n",
    "\n",
    "![Traditional Programming versus Machine Learning](https://cdn.prod.website-files.com/614c82ed388d53640613982e/63ef5f4e24edde6ef055c3b2_traditional%20programming%20vs%20machine%20learning.jpg)\n",
    "\n",
    "### How does it work?\n",
    "\n",
    "1. **Input Data** â€“ The ML model receives a large amount of data, such as images, text, numbers, or sounds.\n",
    "\n",
    "2. **Training** â€“ The algorithm analyzes the data and \"learns\" relationships between them, adjusting its parameters.\n",
    "\n",
    "3. **Prediction** â€“ After training, the model can process new data and make decisions based on it.\n",
    "\n",
    "### Examples of ML applications:\n",
    "\n",
    "- **Recommendations** (Netflix, Spotify suggesting movies/music)\n",
    "\n",
    "- **Speech and image recognition** (Siri, Google Lens)\n",
    "\n",
    "- **Spam filters** (detecting spam emails)\n",
    "\n",
    "- **Predictive systems** (weather forecasts, financial analysis)\n",
    "\n",
    "### Types of Machine Learning:\n",
    "\n",
    "1. **Supervised Learning** â€“ The model learns from labeled data (e.g., images of cats and dogs, where it knows what is what).\n",
    "\n",
    "2. **Unsupervised Learning** â€“ The model searches for patterns in data without labels (e.g., clustering customers based on similar behavior).\n",
    "\n",
    "![Supervised versus Unsupervised Learning](https://www.mathworks.com/discovery/machine-learning/_jcr_content/mainParsys/band/mainParsys/lockedsubnav/mainParsys/columns/a32c7d5d-8012-4de1-bc76-8bd092f97db8/image_2128876021_cop.adapt.full.medium.svg/1741205964325.svg)\n",
    "\n",
    "### Basic Paradigm of Machine Learning\n",
    "\n",
    "1. Observe set of examples: **training data**.\n",
    "\n",
    "2. Infer something about process that generated that data.\n",
    "\n",
    "3. Use inference to make predictions about previously unseen data: **test data**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised versus Unsupervised Learning\n",
    "\n",
    "Machine learning can be broadly categorized into two main types: **Supervised Learning** and **Unsupervised Learning**. The key difference lies in whether the data used for training includes labeled outputs.\n",
    "\n",
    "![Classification versus Clustering versus Regression](https://lh6.googleusercontent.com/proxy/b9cTY0TniOxMDzL0UEDPN9WdCMqxJ0ETnubKDQ37IIubX6NK1l_iGMkRZTzAdC-Xi3G2V9_jX9PlAQzsUd2g-LLxU7q0qM_KgzKiOeuIodms5uNEVQoy0xEw93U75fZPVT-R_-XN7D4h5L6E)\n",
    "\n",
    "---\n",
    "\n",
    "## Supervised Learning\n",
    "\n",
    "Supervised learning is a type of machine learning where the model learns from **labeled data**. Each training example consists of an input and a corresponding correct output.\n",
    "\n",
    "### How it works:\n",
    "\n",
    "- The algorithm is trained on a dataset containing **inputs (X)** and **expected outputs (Y)**.\n",
    "\n",
    "- The model makes predictions and adjusts itself based on the difference between its predictions and the actual labels.\n",
    "\n",
    "- Once trained, the model can make accurate predictions on new, unseen data.\n",
    "\n",
    "### Examples:\n",
    "\n",
    "- **Email Spam Detection** â€“ Given labeled emails (\"spam\" or \"not spam\"), the model learns to classify new emails.\n",
    "\n",
    "- **Image Classification** â€“ Identifying whether an image contains a cat or a dog.\n",
    "\n",
    "- **Stock Price Prediction** â€“ Predicting future stock prices based on historical labeled data.\n",
    "\n",
    "---\n",
    "\n",
    "## Unsupervised Learning\n",
    "\n",
    "Unsupervised learning deals with **unlabeled data**. The model finds patterns and structures in the data without predefined labels.\n",
    "\n",
    "### How it works:\n",
    "\n",
    "- The algorithm analyzes input data **without any associated outputs**.\n",
    "\n",
    "- It groups similar data points or identifies hidden structures.\n",
    "\n",
    "- Often used for **clustering**, **anomaly detection**, and **pattern recognition**.\n",
    "\n",
    "### Examples:\n",
    "\n",
    "- **Customer Segmentation** â€“ Grouping customers by purchasing behavior.\n",
    "\n",
    "- **Anomaly Detection** â€“ Identifying fraudulent transactions in banking.\n",
    "\n",
    "- **Topic Modeling** â€“ Discovering topics in a collection of documents.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Differences: \n",
    "| Feature              | Supervised Learning | Unsupervised Learning |\n",
    "|----------------------|--------------------|----------------------|\n",
    "| **Data Type**        | Labeled data (X, Y) | Unlabeled data (X) |\n",
    "| **Main Goal**        | Learn a mapping from inputs to outputs | Find hidden structures and patterns |\n",
    "| **Typical Use Cases** | Classification, Regression | Clustering, Anomaly Detection |\n",
    "\n",
    "![Classification versus Clustering](https://cdn.prod.website-files.com/614c82ed388d53640613982e/63ef769f6a877d715fa75008_supervised%20vs%20Unsupervised%20learning.jpg)\n",
    "\n",
    "Both types of learning have unique applications and are used depending on the problem at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "Process of creating, transforming and selecting features used as input for machine learning models. The goal is to improve the quality of the data so the model can learn and make predictions more effectively.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§¬ **Biology: Diagnosing Diseases**\n",
    "\n",
    "**Problem:** Predicting whether a patient has diabetes based on medical data.\n",
    "\n",
    "- **Feature Creation:** Instead of using just raw glucose levels, we create a feature: \n",
    "\n",
    "  **\"Glucose Level Change Rate\"** = (Glucose after meal - Fasting Glucose) / Time  \n",
    "\n",
    "  This helps capture how fast glucose levels rise, which is a better indicator than just one reading.\n",
    "  \n",
    "- **Binning (Discretization):** Categorizing blood pressure as:\n",
    "  - Normal (BP < 120)\n",
    "\n",
    "  - Pre-Hypertension (120 â‰¤ BP < 140)\n",
    "\n",
    "  - Hypertension (BP â‰¥ 140)\n",
    "\n",
    "---\n",
    "\n",
    "### âš¡ **Physics: Predicting Energy Consumption**\n",
    "\n",
    "**Problem:** Predicting electricity usage in a city.\n",
    "\n",
    "- **Feature Extraction:** Instead of using just temperature data, extract:\n",
    "\n",
    "  - **\"Cooling Demand\"** = Max(0, Temperature - 22Â°C)  \n",
    "\n",
    "  - **\"Heating Demand\"** = Max(0, 18Â°C - Temperature)  \n",
    "\n",
    "  This helps separate heating vs. cooling needs.\n",
    "\n",
    "- **Time-Based Features:**  \n",
    "\n",
    "  - **\"Peak Hours\"**: 6 AM â€“ 9 AM, 5 PM â€“ 9 PM (Higher usage during these hours)\n",
    "\n",
    "  - **\"Weekend vs. Weekday\"**: Energy usage patterns differ.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ’° **Economics: Stock Market Prediction**\n",
    "\n",
    "**Problem:** Predicting future stock prices.\n",
    "\n",
    "- **Rolling Averages:** Instead of raw stock prices, calculate:\n",
    "\n",
    "  - **\"7-day Moving Average\"** = Average closing price over the past 7 days.\n",
    "\n",
    "  - **\"Volatility\"** = Standard deviation of stock prices over 30 days.\n",
    "  \n",
    "- **Sentiment Analysis:** Create a **\"Market Sentiment Score\"** from news headlines:\n",
    "\n",
    "  - Positive words like â€œgrowthâ€ â†’ +1  \n",
    "\n",
    "  - Negative words like â€œcrisisâ€ â†’ -1  \n",
    "\n",
    "- **Event-Based Features:**  \n",
    "\n",
    "  - **\"Earnings Report Released?\"** (Yes/No) â†’ Stocks react to earnings reports.\n",
    "\n",
    "---\n",
    "\n",
    "## Avoiding Overfitting\n",
    "\n",
    "### **Biology: Disease Diagnosis**\n",
    "\n",
    "- **Overfit Risk:** The model memorizes specific patients' data instead of generalizing.\n",
    "\n",
    "- **Solution:** Use **cross-validation**, ensuring the model is tested on unseen patients.\n",
    "\n",
    "### **Physics: Energy Prediction**\n",
    "\n",
    "- **Overfit Risk:** The model learns short-term weather noise instead of long-term trends.\n",
    "\n",
    "- **Solution:** Apply **regularization (L1/L2)** to smooth out fluctuations.\n",
    "\n",
    "### **Economics: Stock Prediction**\n",
    "\n",
    "- **Overfit Risk:** The model relies too much on short-term stock price fluctuations.\n",
    "\n",
    "- **Solution:** Use **feature selection** to remove unnecessary variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Measures of Machine Learning Models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
